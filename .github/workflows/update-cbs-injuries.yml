name: Update CBS Injuries

on:
  schedule:
    - cron: '0 10,22 * * *'  # Twice daily: 10:00 and 22:00 UTC
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: pip install requests beautifulsoup4 lxml

      - name: Scrape CBS injuries
        run: |
          python3 -c "
          import json
          import requests
          from bs4 import BeautifulSoup

          url = 'https://www.cbssports.com/nba/injuries/'
          headers = {
              'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',
              'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
              'Accept-Language': 'en-US,en;q=0.5',
          }

          response = requests.get(url, headers=headers, timeout=15)
          response.raise_for_status()

          soup = BeautifulSoup(response.text, 'lxml')
          team_sections = soup.find_all('div', class_='TableBaseWrapper')
          injuries_by_team = []

          for team_section in team_sections:
              team_name_el = team_section.find('div', class_='TeamLogoNameLockup-name')
              if not team_name_el:
                  continue
              team_name = team_name_el.get_text(strip=True)
              players = []
              rows = team_section.find_all('tr', class_='TableBase-bodyTr')
              for row in rows:
                  cells = row.find_all('td', class_='TableBase-bodyTd')
                  name_el = row.find('span', class_='CellPlayerName--long')
                  date_el = row.find('span', class_='CellGameDate')
                  if name_el and len(cells) >= 5:
                      players.append({
                          'name': name_el.get_text(strip=True),
                          'updated': date_el.get_text(strip=True) if date_el else '',
                          'injury': cells[3].get_text(strip=True),
                          'status': cells[4].get_text(strip=True),
                      })
              if players:
                  injuries_by_team.append({'team': team_name, 'players': players})

          from datetime import datetime, timezone
          result = {
              'injuries': injuries_by_team,
              'source': 'CBS Sports',
              'lastUpdated': datetime.now(timezone.utc).strftime('%B %d, %Y %H:%M UTC')
          }

          with open('cbs_injuries.json', 'w', encoding='utf-8') as f:
              json.dump(result, f, ensure_ascii=False, indent=2)

          print(f'Scraped {len(injuries_by_team)} teams')
          "

      - name: Commit and push
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add cbs_injuries.json
          git diff --cached --quiet && echo "No changes" && exit 0
          git commit -m "update CBS injuries data"
          git pull --rebase origin main
          git push

      - name: Deploy to server
        uses: appleboy/ssh-action@v1
        with:
          host: ${{ secrets.SERVER_IP }}
          username: root
          key: ${{ secrets.SSH_PRIVATE_KEY }}
          script: |
            cd /opt/nba_stables
            git pull origin main
            docker cp cbs_injuries.json $(docker ps -q -f name=nba):/app/cbs_injuries.json
